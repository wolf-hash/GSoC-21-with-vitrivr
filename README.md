# GSoC'21 with vitrivr
This will be a blog with my weekly progress. Here is the index - 

## About the Organisation - 
Vitrivr is an open source full-stack content-based multimedia retrieval system with a focus on video. Its modular architecture makes it easy to also search audio, images, 3D Models and structured data. 

## About the Project
Text in a video often conveys information that is not easily expressed otherwise. This project will implement and compare the various existing state-of-the-art scene-text-transcription models and run inference of the best model on Java using legacy Java bindings of Tensorflow.
I am aiming to start with Attention OCR as the initial implementation. My plan will be to write the code such that it is easier for others to swap in models they would like to use with very minimal code modification. Basically making it modular. Here's the [link](https://docs.google.com/document/d/e/2PACX-1vSUpp3oRv9otAFt3gwrI1uThasbFvO02vWtg80JFpYjmjeabKfVd4-sj1mHACDyxUaKWhpZMjMF1YGt/pub) to my proposal.

## About Me
I’m Karan Singh, a second year student from Vellore Institute of Technology (Vellore branch) majoring in Computer Science and Engineering. I’m a programmer who devotes to simplifying the process to get things done and providing convenience  service and application to users. I am currently exploring a lot into Deep Learning along with Image Processing. I have a CGPA of 9.7 and currently ranked 3rd in my university in Computer Science.

I have been fascinated by Deep Learning for the past 5 years but Geoffrey Hinton’s paper on Capsule Networks is what pushed me more towards the computer vision tranche. I am fluent with languages including Python, C/C++, Java, JavaScript and have experience of over two years using Tensorflow, Object Detection API and Django web framework. I have worked on a few similar projects that have required Object Detection and image processing.

I am really looking forward to working with the organisation and also just to be a part of this amazing open source community.
